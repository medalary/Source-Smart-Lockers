import os
import cv2
import time
import tkinter as tk
from tkinter import font, Button, SUNKEN, messagebox, Toplevel, Label, simpledialog
from PIL import Image, ImageTk
import subprocess
import shutil 
import threading
import queue 

# Imports for Face Recognition (from train.py)
import numpy as np
import pickle
# Try importing MTCNN and FaceNet. If not found, show a warning and disable recognition.
try:
    from mtcnn import MTCNN
    from keras_facenet import FaceNet
    FACENET_AVAILABLE = True
except ImportError:
    # Use a placeholder message, as show_temp_toplevel_message might not be defined yet
    print("Warning: 'mtcnn' or 'keras_facenet' library not found. Face recognition functions will be disabled.")
    FACENET_AVAILABLE = False
except Exception as e:
    print(f"Warning: Error loading FaceNet libraries: {e}. Face recognition functions will be disabled.")
    FACENET_AVAILABLE = False

# === Function to display temporary Toplevel messages ===
def show_temp_toplevel_message(title, message, delay=2000):
    top = Toplevel(window)
    top.title(title)
    # Position the Toplevel in the center of the main window for better visibility
    x = window.winfo_x() + (window.winfo_width() // 2) - 150 # Adjust 150 based on expected Toplevel width
    y = window.winfo_y() + (window.winfo_height() // 2) - 50  # Adjust 50 based on expected Toplevel height
    top.geometry(f"+{x}+{y}")
    top.transient(window) # Make it appear on top of the main window
    top.grab_set() # Make it modal
    top.attributes('-topmost', True) # Ensure it stays on top

    label = Label(top, text=message, padx=20, pady=20, font=("Arial", 12))
    label.pack()

    # Automatically destroy after 'delay' milliseconds
    top.after(delay, top.destroy)

    # Allow the window manager to update its state
    window.update_idletasks()

try:
    from gpiozero import InputDevice, OutputDevice, GPIODeviceError
    GPIO_AVAILABLE = True
except ImportError:
    show_temp_toplevel_message("GPIO Warning", "The 'gpiozero' library was not found. GPIO functions will be disabled.")
    GPIO_AVAILABLE = False
except Exception as e:
    show_temp_toplevel_message("GPIO Warning", f"Error loading 'gpiozero': {e}. GPIO functions will be disabled.")
    GPIO_AVAILABLE = False

# === Add these Global Queues and Thread Control Flags ===
recognition_task_queue = queue.Queue()  # Used to send frames to the recognition worker thread
recognition_result_queue = queue.Queue() # Used to receive results from the recognition worker thread
recognition_thread = None # Reference to the recognition worker thread
thread_running = False # Flag to control the worker thread's loop
# --------------------------------------------------------

# === Constants ===
LOCKER_COUNT = 4
AVAILABLE_FILE = "available.txt"
DATASET_DIR = "dataset" # For SEND (adding new users/items to lockers)
CAPTURED_DIR = "captured" # For GET/ADD (recognition images, temporary)
# Path to the embeddings file generated by train.py
EMBEDDINGS_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), "Code", "embeddings", "face_cosine_data.pkl")
RECOGNITION_THRESHOLD = 0.75 # Cosine similarity threshold for face recognition (can be adjusted)

# Camera Configuration from cam.py
CAMERA_WIDTH = 1200
CAMERA_HEIGHT = 2048
CAMERA_INDEX = 0
# FULLSCREEN_MODE is handled dynamically for the Toplevel camera window
WINDOW_TITLE_CAMERA = "Smart Locker Camera Interface"

BORDER_COLOR = (0, 255, 0)
BORDER_THICKNESS = 10
BORDER_WIDTH_RATIO = 0.7
BORDER_HEIGHT_RATIO = 0.6
BORDER_RADIUS = 30
SHORT_LINE_LENGTH = 50

# New constant for camera display duration after recognition (for ADD/GET)
POST_RECOGNITION_CAMERA_DURATION_MS = 500 # Keep camera open for 5 seconds after recognition

# GPIO Pin Configuration
INPUT_GPIO_PINS = {
    1: 21,  # Pick_ID[1] corresponds to GPIO 21
    2: 20,  # Pick_ID[2] corresponds to GPIO 20
    3: 16,  # Pick_ID[3] corresponds to GPIO 16
    4: 12   # Pick_ID[4] corresponds to GPIO 12
}

OUTPUT_GPIO_PINS = {
    1: 1,   # Pick_ID[0]=1 activates GPIO 1
    2: 7,   # Pick_ID[0]=2 activates GPIO 7
    3: 8,   # Pick_ID[0]=3 activates GPIO 8
    4: 25   # Pick_ID[0]=4 activates GPIO 25
}

# === Initialize GPIO Devices ===
input_devices = {}
output_devices = {}
if GPIO_AVAILABLE:
    for i, pin_num in INPUT_GPIO_PINS.items():
        try:
            input_devices[i] = InputDevice(pin_num, pull_up=True)
            print(f"GPIO {pin_num} configured as input with pull-up.")
        except GPIODeviceError as e:
            show_temp_toplevel_message("GPIO Error", f"Error initializing GPIO {pin_num} (Input): {e}. Please ensure the pin is correct and permissions are granted.")
            GPIO_AVAILABLE = False
            break
    for i, pin_num in OUTPUT_GPIO_PINS.items():
        try:
            output_devices[i] = OutputDevice(pin_num, initial_value=False) # Initialize at LOW
            print(f"GPIO {pin_num} configured as output.")
        except GPIODeviceError as e:
            show_temp_toplevel_message("GPIO Error", f"Error initializing GPIO {pin_num} (Output): {e}. Please ensure the pin is correct and permissions are granted.")
            GPIO_AVAILABLE = False
            break

# Global variable for Pick_ID
# Pick_ID[0] will be the calculated result (index of the first available locker).
# Pick_ID[1] through Pick_ID[4] will be the status read from GPIO.
Pick_ID = [0, 0, 0, 0, 0]

# Load the pre-trained face cascade classifier
# Make sure 'haarcascade_frontalface_default.xml' is available in your OpenCV data path
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
if face_cascade.empty():
    show_temp_toplevel_message("Face Detection Error", "Could not load face cascade classifier. Make sure 'haarcascade_frontalface_default.xml' is in your OpenCV data path.")

# Load the pre-trained eye cascade classifier
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
if eye_cascade.empty():
    show_temp_toplevel_message("Eye Detection Error", "Could not load eye cascade classifier. Make sure 'haarcascade_eye.xml' is in your OpenCV data path.")

# Load the pre-trained smile cascade classifier
smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')
if smile_cascade.empty():
    show_temp_toplevel_message("Smile Detection Error", "Could not load smile cascade classifier. Make sure 'haarcascade_smile.xml' is in your OpenCV data path.")


# Initialize FaceNet and MTCNN globally if available
if FACENET_AVAILABLE:
    embedder = FaceNet()
    detector = MTCNN()
else:
    embedder = None
    detector = None

# === Helper: Face Extraction for Recognition ===
def extract_face_from_img_array(img_array, required_size=(160, 160)):
    """Extracts a face from an image (numpy array) using MTCNN."""
    if img_array is None:
        return None
    
    if detector is None: # Fallback if MTCNN is not initialized
        print("MTCNN detector not available for face extraction.")
        return None

    results = detector.detect_faces(img_array)
    if len(results) == 0:
        return None
    
    # Get the first detected face
    x, y, w, h = results[0]['box']
    
    # Ensure coordinates are within image bounds
    h_img, w_img, _ = img_array.shape
    x1, y1 = max(0, x), max(0, y)
    x2, y2 = min(w_img, x + w), min(h_img, y + h)

    face = img_array[y1:y2, x1:x2]
    
    if face.shape[0] == 0 or face.shape[1] == 0: # Handle cases where crop results in empty image
        return None

    try:
        face = cv2.resize(face, required_size)
    except cv2.error as e:
        print(f"Error resizing face: {e}")
        return None
    return face

# === Helper: Perform Face Recognition ===
def perform_face_recognition(captured_image_array):
    """
    Performs face recognition on a captured image array using pre-trained embeddings.
    Returns the matched locker ID (integer) or 0 if no match.
    """
    if not FACENET_AVAILABLE:
        print("FaceNet libraries not available, skipping recognition.")
        return 0

    if not os.path.exists(EMBEDDINGS_FILE):
        show_temp_toplevel_message("Recognition Error", "Embeddings file not found. Please run 'train.py' first.")
        return 0

    try:
        with open(EMBEDDINGS_FILE, "rb") as f:
            face_data = pickle.load(f)
    except Exception as e:
        show_temp_toplevel_message("Recognition Error", f"Error loading embeddings: {e}")
        return 0

    extracted_face = extract_face_from_img_array(captured_image_array)
    if extracted_face is None:
        print("No face detected in the captured image for recognition.")
        return 0

    try:
        candidate_embedding = embedder.embeddings([extracted_face])[0]
    except Exception as e:
        show_temp_toplevel_message("Recognition Error", f"Error generating embedding: {e}")
        return 0

    best_match_id = 0
    highest_similarity = -1.0

    for person_name_str, embeddings_list in face_data.items():
        try:
            person_id = int(person_name_str) # Assume person_name is the locker ID
        except ValueError:
            print(f"Warning: Non-integer person name '{person_name_str}' in embeddings. Skipping.")
            continue

        for stored_embedding in embeddings_list:
            # Calculate cosine similarity
            similarity = np.dot(candidate_embedding, stored_embedding) / \
                         (np.linalg.norm(candidate_embedding) * np.linalg.norm(stored_embedding))
            
            if similarity > highest_similarity and similarity >= RECOGNITION_THRESHOLD:
                highest_similarity = similarity
                best_match_id = person_id
    
    if best_match_id != 0:
        print(f"Recognized as Locker ID {best_match_id} with similarity {highest_similarity:.4f}")
    else:
        print("No matching face found above threshold.")

    return best_match_id
# === Add this Function for the Recognition Worker Thread ===
def recognition_worker():
    global thread_running
    thread_running = True
    print("Recognition worker thread started.")
    while thread_running:
        try:
            # Wait for a frame from the queue, with a timeout to allow checking thread_running flag
            frame_to_recognize = recognition_task_queue.get(timeout=1)
            if frame_to_recognize is None: # This is the termination signal
                print("Recognition worker received termination signal.")
                break

            print("Worker: Performing face recognition...")
            # Call the computationally intensive recognition function
            matched_id = perform_face_recognition(frame_to_recognize)
            print(f"Worker: Recognition finished, matched_id={matched_id}")
            recognition_result_queue.put(matched_id) # Put the result into the result queue
            recognition_task_queue.task_done() # Mark the task as done

        except queue.Empty:
            # Queue was empty, continue loop and check thread_running flag
            continue
        except Exception as e:
            print(f"Worker: An error occurred during recognition: {e}")
            # Put an error value into the result queue for the main thread to handle
            recognition_result_queue.put(0) # Or another special value for errors
            recognition_task_queue.task_done()
    print("Recognition worker thread stopped.")
# -----------------------------------------------------------

# === Helper: Available Lockers State ===
def read_available_lockers():
    if os.path.exists(AVAILABLE_FILE):
        with open(AVAILABLE_FILE, "r") as f:
            try:
                return int(f.read().strip())
            except ValueError:
                return LOCKER_COUNT # Fallback if file content is invalid
    return LOCKER_COUNT

def write_available_lockers(count):
    with open(AVAILABLE_FILE, "w") as f:
        f.write(str(count))

# === Function to draw rounded corners and lines (UPDATED) ===
def draw_rounded_corners_with_lines(image, p1, p2, color, thickness, r, line_length):
    x1, y1 = p1
    x2, y2 = p2

    cv2.ellipse(image, (x1 + r, y1 + r), (r, r), 180, 0, 90, color, thickness)
    cv2.ellipse(image, (x2 - r, y1 + r), (r, r), 270, 0, 90, color, thickness)
    cv2.ellipse(image, (x1 + r, y2 - r), (r, r), 90, 0, 90, color, thickness)
    cv2.ellipse(image, (x2 - r, y2 - r), (r, r), 0, 0, 90, color, thickness)

    cv2.line(image, (x1 + r, y1), (x1 + r + line_length, y1), color, thickness)
    cv2.line(image, (x2 - r, y1), (x2 - r - line_length, y1), color, thickness)

    cv2.line(image, (x1 + r, y2), (x1 + r + line_length, y2), color, thickness)
    cv2.line(image, (x2 - r, y2), (x2 - r - line_length, y2), color, thickness)

    cv2.line(image, (x1, y1 + r), (x1, y1 + r + line_length), color, thickness)
    cv2.line(image, (x1, y2 - r), (x1, y2 - r - line_length), color, thickness)

    cv2.line(image, (x2, y1 + r), (x2, y1 + r + line_length), color, thickness)
    cv2.line(image, (x2, y2 - r), (x2, y2 - r - line_length), color, thickness)


# === Function to update Pick_ID status from GPIO (from PickID.py) ===
def update_pick_id_status():
    global Pick_ID
    if not GPIO_AVAILABLE:
        print("GPIO not available, cannot update Pick_ID.")
        # Mock Pick_ID for testing if GPIO is not available
        current_available = read_available_lockers()
        mock_pick_id = [0, 0, 0, 0, 0] # Start with all available
        for i in range(1, LOCKER_COUNT + 1):
            if i > current_available: # Simple mock: if we have 2 available, lockers 1,2 are 0, 3,4 are 1
                 mock_pick_id[i] = 1 # Mark as in use if beyond available count
        # Find first available mock locker
        found_mock_available = False
        for i in range(1, LOCKER_COUNT + 1):
            if mock_pick_id[i] == 0:
                mock_pick_id[0] = i
                found_mock_available = True
                break
        if not found_mock_available:
            mock_pick_id[0] = 0 # No lockers available
        Pick_ID = mock_pick_id
        return Pick_ID

    for i in range(1, 5):
        # input_devices[i].value returns True (1) if HIGH (in use), False (0) if LOW (available)
        # We map True to 1 (in use) and False to 0 (available)
        Pick_ID[i] = 0 if input_devices[i].value else 1 # 0 if available, 1 if in use

    # --- Calculate value for Pick_ID[0] ---
    # Find the index (from 1 to 4) of the first locker with status 0 (available).
    # If no locker has status 0, Pick_ID[0] will be 0.
    found_available_locker = False
    for i in range(1, 5):
        if Pick_ID[i] == 0:
            Pick_ID[0] = i  # Store the index of the available locker
            found_available_locker = True
            break

    if not found_available_locker:
        Pick_ID[0] = 0 # No lockers available

    print(f"Updated Pick_ID: {Pick_ID}")
    return Pick_ID

# === Update available lockers display ===
def update_available_display():
    global Pick_ID
    # Count the number of available lockers (value 0 from Pick_ID[1] to Pick_ID[4])
    available_count = sum(1 for i in range(1, 5) if Pick_ID[i] == 0)
    locker_var.set(str(available_count))
    write_available_lockers(available_count) # Update the available.txt file

# === Main GUI Setup ===
window = tk.Tk()
window.title("SMART LOCKERS")
window.geometry("600x1024")
window.configure(bg="#BCD2EE")

# === Fonts ===
big_font_bold = font.Font(family="Tahoma", size=40, weight="bold")
normal_font_bold = font.Font(family="Tahoma", size=26, weight="bold")
normal_font = font.Font(family="Tahoma", size=20)
small_font = font.Font(family="Tahoma", size=14)

# === Header ===
canvas = tk.Canvas(window, width=600, height=128, bg="#FFFFFF")
canvas.place(x=0, y=0)
# Check for image file existence
logo_path = "picture/logo.jpg"
if os.path.exists(logo_path):
    logo = Image.open(logo_path).resize((400, 128))
    header = ImageTk.PhotoImage(logo)
    canvas.create_image(100, 0, image=header, anchor=tk.NW)
else:
    canvas.create_text(300, 64, text="SMART LOCKERS", font=big_font_bold, fill="#191970", anchor="center")
    print(f"Warning: Logo file not found at '{logo_path}'.")


# === Title ===
tk.Label(window, text="SMART LOCKER", font=big_font_bold, fg="#191970", bg="#BCD2EE").pack(pady=(135, 0))
tk.Label(window, text="APPLYING FACE DETECTION & IOT", font=normal_font, fg="#666666", bg="#BCD2EE").pack()

# === Available Lockers ===
# Update Pick_ID and display available locker count on startup
update_pick_id_status()
current_available_lockers = sum(1 for i in range(1, 5) if Pick_ID[i] == 0)
locker_var = tk.StringVar(value=str(current_available_lockers))

frame = tk.Frame(window, bg="#BCD2EE", pady=10)
frame.pack()
tk.Label(frame, text="Available lockers:", font=normal_font_bold, fg="#B22222", bg="#BCD2EE").pack(side="left")
tk.Entry(frame, textvariable=locker_var, font=normal_font_bold, width=3, justify="center", fg="#B22222", bg="#FFFFE0", state='readonly').pack(side="left", padx=5)


# === Helper: Open Camera for Recognition (for ADD/GET) ===
def open_camera_for_recognition(action_type):
    global Pick_ID, recognition_thread, thread_running

    if recognition_thread is None or not recognition_thread.is_alive():
        recognition_thread = threading.Thread(target=recognition_worker, daemon=True)
        recognition_thread.start()
        time.sleep(0.1)

    camera_window = Toplevel(window)
    camera_window.title(WINDOW_TITLE_CAMERA)

    screen_width = camera_window.winfo_screenwidth()
    screen_height = camera_window.winfo_screenheight()

    camera_window.geometry(f"{screen_width}x{screen_height}+0+0")
    camera_window.attributes('-fullscreen', True)
    camera_window.bind('<Escape>', lambda e: camera_window.destroy())
    print("Press Esc to exit camera full-screen mode.")

    camera_label = Label(camera_window, bg="black")
    camera_label.pack(fill=tk.BOTH, expand=True)

    face_status_label = Label(camera_window, text="No Face Detected", font=("Arial", 20, "bold"), fg="red", bg="black")
    face_status_label.place(relx=0.5, rely=0.05, anchor=tk.N)

    cap = cv2.VideoCapture(CAMERA_INDEX)
    if not cap.isOpened():
        show_temp_toplevel_message("Camera Error", "Cannot access camera. Please check connection.")
        camera_window.destroy()
        return None, None

    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
    camera_window.update_idletasks()

    matched_locker_id = None
    is_recognition_in_progress = False 
    closing_scheduled = False 

    def check_recognition_results():
        nonlocal matched_locker_id, is_recognition_in_progress, closing_scheduled
        try:
            result_id = recognition_result_queue.get_nowait()
            
            is_recognition_in_progress = False 
            
            matched_locker_id = result_id 
            
            if matched_locker_id != 0: 
                show_temp_toplevel_message("Recognition", f"Face matched to Locker {matched_locker_id}.")
            else: 
                show_temp_toplevel_message("Recognition", "No match found for this face.")
                
            if not closing_scheduled:
                closing_scheduled = True
                camera_window.after(POST_RECOGNITION_CAMERA_DURATION_MS, lambda: [cap.release(), camera_window.destroy()])
                print(f"Camera scheduled to close in {POST_RECOGNITION_CAMERA_DURATION_MS/1000} seconds after recognition.")
            
        except queue.Empty:
            pass
        finally:
            if camera_window.winfo_exists() and not closing_scheduled:
                camera_label.after(100, check_recognition_results) 
    
    camera_label.after(100, check_recognition_results)
    
    def update_recognition_feed():
        nonlocal matched_locker_id, closing_scheduled, is_recognition_in_progress 
        ret, frame = cap.read()
        if ret:
            display_frame = cv2.flip(frame, 1)

            label_width = camera_label.winfo_width()
            label_height = camera_label.winfo_height()

            if label_width <= 1 or label_height <= 1:
                label_width = screen_width
                label_height = screen_height

            target_aspect_ratio = label_width / label_height
            original_h, original_w, _ = display_frame.shape
            original_aspect_ratio = original_w / original_h

            crop_x, crop_y, crop_w, crop_h = 0, 0, original_w, original_h

            if original_aspect_ratio > target_aspect_ratio:
                crop_w = int(original_h * target_aspect_ratio)
                crop_x = (original_w - crop_w) // 2
            else:
                crop_h = int(original_w / target_aspect_ratio)
                crop_y = (original_h - crop_h) // 2

            cropped_display_frame = display_frame[crop_y : crop_y + crop_h, crop_x : crop_x + crop_w]

            gray = cv2.cvtColor(cropped_display_frame, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, 1.1, 4, minSize=(30, 30))

            detection_count = len(faces) # Simplified detection count to only faces for this refactor

            # Calculate border coordinates based on the cropped frame
            border_w = int(cropped_display_frame.shape[1] * BORDER_WIDTH_RATIO)
            border_h = int(cropped_display_frame.shape[0] * BORDER_HEIGHT_RATIO)
            border_x1 = (cropped_display_frame.shape[1] - border_w) // 2
            border_y1 = (cropped_display_frame.shape[0] - border_h) // 2
            border_x2 = border_x1 + border_w
            border_y2 = border_y1 + border_h

            draw_rounded_corners_with_lines(cropped_display_frame, (border_x1, border_y1), (border_x2, border_y2), BORDER_COLOR, BORDER_THICKNESS, BORDER_RADIUS, SHORT_LINE_LENGTH)

            if detection_count > 0: # Check if any face is detected
                face_status_label.config(text="Face Detected!", fg="green")
                
                if not is_recognition_in_progress and not closing_scheduled:
                    print("Main Thread: Face detected, sending frame to recognition worker.")
                    recognition_task_queue.put(frame.copy())
                    is_recognition_in_progress = True 
            else: 
                face_status_label.config(text="No Face Detected", fg="red")
                if is_recognition_in_progress: # If a face was previously detected
                    print("Face lost, resetting recognition attempt and clearing queues.")
                    is_recognition_in_progress = False 
                    while not recognition_task_queue.empty():
                        try:
                            recognition_task_queue.get_nowait()
                        except queue.Empty:
                            pass
                    while not recognition_result_queue.empty():
                        try:
                            recognition_result_queue.get_nowait()
                        except queue.Empty:
                            pass

            cv2_image = cv2.cvtColor(cropped_display_frame, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(cv2_image)
            pil_image = pil_image.resize((label_width, label_height), Image.LANCZOS)
            tk_image = ImageTk.PhotoImage(image=pil_image)

            camera_label.imgtk = tk_image
            camera_label.config(image=tk_image)
            
            if not closing_scheduled:
                camera_label.after(10, update_recognition_feed)
        else:
            show_temp_toplevel_message("Camera Error", "Failed to read frame from camera.")
            cap.release()
            camera_window.destroy()
    camera_label.after(10, update_recognition_feed)

    window.wait_window(camera_window)

    return matched_locker_id

# === Helper: Open Camera for Image Capture (for SEND) ===
def open_camera_for_capture(user_folder):
    camera_window = Toplevel(window)
    camera_window.title(WINDOW_TITLE_CAMERA)

    screen_width = camera_window.winfo_screenwidth()
    screen_height = camera_window.winfo_screenheight()

    camera_window.geometry(f"{screen_width}x{screen_height}+0+0")
    camera_window.attributes('-fullscreen', True)
    camera_window.bind('<Escape>', lambda e: camera_window.destroy())
    print("Press Esc to exit camera full-screen mode.")

    camera_label = Label(camera_window, bg="black")
    camera_label.pack(fill=tk.BOTH, expand=True)

    face_status_label = Label(camera_window, text="No Face Detected", font=("Arial", 20, "bold"), fg="red", bg="black")
    face_status_label.place(relx=0.5, rely=0.05, anchor=tk.N)

    cap = cv2.VideoCapture(CAMERA_INDEX)
    if not cap.isOpened():
        show_temp_toplevel_message("Camera Error", "Cannot access camera. Please check connection.")
        camera_window.destroy()
        return False

    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
    camera_window.update_idletasks()

    captured_images_paths = []
    total_images_to_capture = 8
    captured_count = 0
    start_time_capture = None
    capture_interval = 0.5 

    def update_camera_feed_send():
        nonlocal captured_count, start_time_capture
        ret, frame = cap.read()
        if ret:
            display_frame = cv2.flip(frame, 1)

            label_width = camera_label.winfo_width()
            label_height = camera_label.winfo_height()

            if label_width <= 1 or label_height <= 1:
                label_width = screen_width
                label_height = screen_height

            target_aspect_ratio = label_width / label_height
            original_h, original_w, _ = display_frame.shape
            original_aspect_ratio = original_w / original_h

            crop_x, crop_y, crop_w, crop_h = 0, 0, original_w, original_h

            if original_aspect_ratio > target_aspect_ratio:
                crop_w = int(original_h * target_aspect_ratio)
                crop_x = (original_w - crop_w) // 2
            else:
                crop_h = int(original_w / target_aspect_ratio)
                crop_y = (original_h - crop_h) // 2

            cropped_display_frame = display_frame[crop_y : crop_y + crop_h, crop_x : crop_x + crop_w]

            gray = cv2.cvtColor(cropped_display_frame, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, 1.1, 4, minSize=(30, 30))

            detection_count = len(faces) # Simplified detection count to only faces

            border_w = int(cropped_display_frame.shape[1] * BORDER_WIDTH_RATIO)
            border_h = int(cropped_display_frame.shape[0] * BORDER_HEIGHT_RATIO)
            border_x1 = (cropped_display_frame.shape[1] - border_w) // 2
            border_y1 = (cropped_display_frame.shape[0] - border_h) // 2
            border_x2 = border_x1 + border_w
            border_y2 = border_y1 + border_h

            draw_rounded_corners_with_lines(cropped_display_frame, (border_x1, border_y1), (border_x2, border_y2), BORDER_COLOR, BORDER_THICKNESS, BORDER_RADIUS, SHORT_LINE_LENGTH)

            if detection_count > 0:
                face_status_label.config(text="Face Detected!", fg="green")
            else:
                face_status_label.config(text="No Face Detected", fg="red")

            cv2_image = cv2.cvtColor(cropped_display_frame, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(cv2_image)

            pil_image = pil_image.resize((label_width, label_height), Image.LANCZOS)
            tk_image = ImageTk.PhotoImage(pil_image)

            camera_label.imgtk = tk_image
            camera_label.config(image=tk_image)

            if detection_count > 0 and captured_count < total_images_to_capture:
                if start_time_capture is None:
                    start_time_capture = time.time()
                    print("Face detected, starting image capture timer.")

                if (time.time() - start_time_capture) >= (capture_interval * captured_count):
                    path = os.path.join(user_folder, f"image_{captured_count + 1}.jpg")
                    cv2.imwrite(path, frame)
                    captured_images_paths.append(path)
                    captured_count += 1
                    print(f"Saved image: {path}")
            elif detection_count == 0 and start_time_capture is not None:
                start_time_capture = None
                captured_count = 0
                captured_images_paths.clear()
                print("Face lost, resetting image capture.")

        if captured_count < total_images_to_capture:
            camera_label.after(10, update_camera_feed_send)
        else:
            cap.release()
            camera_window.destroy()
    
    camera_label.after(10, update_camera_feed_send)
    window.wait_window(camera_window)
    
    return len(captured_images_paths) > 0 # Return True if images were captured, False otherwise

# === Helper: Control Locker GPIO ===
def control_locker_gpio(locker_id, duration=1):
    if GPIO_AVAILABLE:
        try:
            output_devices[locker_id].on()
            show_temp_toplevel_message("Open Locker", f"Opened Locker {locker_id}.")
            window.update_idletasks()
            time.sleep(duration)
            output_devices[locker_id].off()
            window.update_idletasks()
            return True
        except KeyError:
            show_temp_toplevel_message("GPIO Error", f"Output GPIO pin not found for locker {locker_id}.")
            return False
        except Exception as e:
            show_temp_toplevel_message("GPIO Error", f"Error controlling output GPIO: {e}")
            return False
    else:
        show_temp_toplevel_message("GPIO Warning", "GPIO not available, cannot control locker.")
        return False # Indicate that GPIO operation was not performed

# === Helper: Handle Locker Completion Logic ===
def handle_locker_completion(locker_id, user_folder_path, action_type):
    """
    Handles the post-operation logic for locker interactions (SEND, GET, ADD).
    action_type: 'send', 'get', 'add'
    """
    message_text = ""
    if action_type == 'send':
        message_text = "Press OK if you have finished depositing items."
    elif action_type == 'get':
        message_text = "Press OK if you have finished retrieving items."
    elif action_type == 'add':
        message_text = "Press OK if you have finished adding more items."
    
    messagebox.showinfo("Confirmation", message_text)
    window.update_idletasks()

    if GPIO_AVAILABLE:
        try:
            final_locker_status_available = input_devices[locker_id].value 
            if not final_locker_status_available:
                if action_type == 'send':
                    show_temp_toplevel_message("Training", "Training ...")
                    try:
                        subprocess.run(["python", "train.py"], check=True)
                        show_temp_toplevel_message("Training", "Training completed.")
                    except FileNotFoundError:
                        show_temp_toplevel_message("Error", "Could not find 'train.py' file for retraining.")
                    except Exception as e:
                        show_temp_toplevel_message("Training Error", f"Error running 'train.py' during retraining: {e}")
                elif action_type in ['get', 'add']:
                    show_temp_toplevel_message("Locker Status", "Locker is still in use.")
                    
            else: 
                show_temp_toplevel_message("Locker Status", "Locker is empty.")
                if os.path.exists(user_folder_path):
                    shutil.rmtree(user_folder_path)
                    print(f"Deleted locker folder: {user_folder_path}")
                else:
                    print(f"Locker folder not found: {user_folder_path}")
                    
                show_temp_toplevel_message("Training", "Retraining ...")
                try:
                    subprocess.run(["python", "train.py"], check=True)
                    show_temp_toplevel_message("Training", "Retraining completed.")
                except FileNotFoundError:
                    show_temp_toplevel_message("Error", "Could not find 'train.py' file for retraining.")
                except Exception as e:
                    show_temp_toplevel_message("Training Error", f"Error running 'train.py' during retraining: {e}")
        except KeyError:
            show_temp_toplevel_message("GPIO Error", f"Input GPIO pin not found for locker {locker_id}.")
        except Exception as e:
            show_temp_toplevel_message("GPIO Error", f"Error checking input GPIO: {e}")
    update_pick_id_status()
    update_available_display()

# === Refactored SEND Function ===
def send_button():
    update_pick_id_status()
    locker_to_open_index = Pick_ID[0]

    if locker_to_open_index == 0:
        show_temp_toplevel_message("Locker Full", "All lockers are currently in use.")
        return
    
    idx = 1
    while os.path.exists(os.path.join(DATASET_DIR, f"{idx}")):
        idx += 1
    user_folder = os.path.join(DATASET_DIR, f"{idx}")
    os.makedirs(user_folder, exist_ok=True) # Ensure directory exists

    if not open_camera_for_capture(user_folder):
        print("Image capture failed or cancelled. Cleaning up user folder.")
        if os.path.exists(user_folder) and not os.listdir(user_folder):
            shutil.rmtree(user_folder)
        return

    # Activate locker and proceed to confirmation
    if control_locker_gpio(locker_to_open_index):
        handle_locker_completion(locker_to_open_index, user_folder, 'send')
    else:
        # If GPIO control failed, but images were captured, still try to train
        show_temp_toplevel_message("Warning", "Locker might not have opened via GPIO, but images were captured.")
        handle_locker_completion(locker_to_open_index, user_folder, 'send')


# === Refactored GET Function ===
def get_button():
    matched_locker_id = open_camera_for_recognition('get')

    if matched_locker_id is None:
        show_temp_toplevel_message("Recognition Failed", "Could not recognize your face! Please try again.")
        return

    if matched_locker_id == 0: 
        show_temp_toplevel_message("Recognition Failed", "No matching face found for any locker.")
        return

    locker_folder_path = os.path.join(DATASET_DIR, f"{matched_locker_id}")

    if control_locker_gpio(matched_locker_id):
        handle_locker_completion(matched_locker_id, locker_folder_path, 'get')
    else:
        # If GPIO control failed, but face was recognized, proceed with data logic assuming intent
        handle_locker_completion(matched_locker_id, locker_folder_path, 'get')


# === Refactored ADD Function ===
def add_button():
    matched_locker_id = open_camera_for_recognition('add')

    if matched_locker_id is None:
        show_temp_toplevel_message("Recognition Failed", "Could not recognize your face! Please try again.")
        return

    if matched_locker_id == 0: 
        show_temp_toplevel_message("Recognition Failed", "No matching face found. Cannot add items to an unrecognized locker.")
        return

    locker_folder_path = os.path.join(DATASET_DIR, f"{matched_locker_id}")

    if control_locker_gpio(matched_locker_id):
        handle_locker_completion(matched_locker_id, locker_folder_path, 'add')
    else:
        # If GPIO control failed, but face was recognized, proceed with data logic assuming intent
        handle_locker_completion(matched_locker_id, locker_folder_path, 'add')


# === Create Image Button ===
def create_image_button(x, y, img1_path, img2_path, command):
    # Check for image file existence
    if not os.path.exists(img1_path) or not os.path.exists(img2_path):
        show_temp_toplevel_message("Button Warning", f"Button image '{img1_path}' or '{img2_path}' not found. Button will display as text.")
        btn = Button(window, text=command.__name__.replace('_button', '').upper(), font=normal_font_bold,
                     bg="#BCD2EE", fg="#191970", cursor="hand2", command=command, relief=SUNKEN,
                     width=10, height=2)
        btn.place(x=x, y=y)
        return

    img1 = ImageTk.PhotoImage(Image.open(img1_path))
    img2 = ImageTk.PhotoImage(Image.open(img2_path))

    btn = Button(window, image=img1, bg="#BCD2EE", border=0, cursor="hand2", relief=SUNKEN)
    btn.image1, btn.image2 = img1, img2 # Keep reference so photo is not garbage collected

    # Function to run when the mouse button is pressed down
    def on_button_press(e):
        btn.config(image=btn.image2) # Change to the "pressed" image (img2)

    # Function to run when the mouse button is released
    def on_button_release(e):
        # Execute the original command
        command()
        # Schedule the image to revert to image1 after 1 second
        btn.after(1000, lambda: btn.config(image=btn.image1))

    # Bind events
    btn.bind("<ButtonPress-1>", on_button_press)
    btn.bind("<ButtonRelease-1>", on_button_release)

    btn.place(x=x, y=y)
    return btn

# === Load Buttons ===
create_image_button(100, 340, "picture/BUTTON/SEND_1.png", "picture/BUTTON/SEND_2.png", send_button)
create_image_button(100, 520, "picture/BUTTON/ADD_1.png", "picture/BUTTON/ADD_2.png", add_button)
create_image_button(100, 700, "picture/BUTTON/GET_1.png", "picture/BUTTON/GET_2.png", get_button)

# === Footer ===
footer = tk.Frame(window, bg="#FFFFFF", pady=8)
footer.pack(fill="x", side="bottom")
tk.Label(footer, text="Pham Lu Huy Chuong - 2188201100\nTran Minh Thien - 2188200439", font=small_font, fg="#666666", bg="#FFFFFF", justify="center").pack()

# === Handle Window Closing ===
def on_closing():
    global thread_running, recognition_thread 
    print("Closing application and releasing resources.")
    
    if recognition_thread is not None and recognition_thread.is_alive():
        print("Sending termination signal to recognition worker thread.")
        thread_running = False 
        recognition_task_queue.put(None) 
        recognition_thread.join(timeout=5) 
        if recognition_thread.is_alive():
            print("Warning: Recognition thread did not terminate gracefully.")
    
    if GPIO_AVAILABLE:
        for device in input_devices.values():
            device.close()
        for device in output_devices.values():
            device.close()
        print("GPIO devices closed.")
    window.destroy()

window.protocol("WM_DELETE_WINDOW", on_closing)

# Run the main Tkinter loop
window.mainloop()